services:
  fastapi:
    build: .
    container_name: ml-api
    restart: unless-stopped
    # Load environment variables from the local .env file
    env_file:
      - .env
    # Expose port 8000 to the host machine
    # This allows your existing Nginx (running on localhost) to Proxy_Pass to http://localhost:8000
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3